# Kubernetes Networking & NetworkPolicy ‚Äì Hands-On Guide (Kind Cluster)

## 1Ô∏è‚É£ Kubernetes Networking Basics

The scalability of Kubernetes allows you to run multiple applications inside a single cluster.

However, **by default Kubernetes does NOT provide network isolation** ‚Äî all Pods can freely communicate with each other.

To control this communication, Kubernetes provides **NetworkPolicy** objects.

---

## 2Ô∏è‚É£ Example Environment ‚Äì Kind Cluster

We provisioned a cluster using:

Kind (Kubernetes IN Docker)

Cluster name: `cka-qacluster`
Nodes: 1 control-plane + 3 worker nodes

```bash
kubectl get nodes
```

Output:

```
NAME                          STATUS   ROLES           AGE   VERSION
cka-qacluster-control-plane   Ready    control-plane   19d   v1.31.0
cka-qacluster-worker          Ready    <none>          19d   v1.31.0
cka-qacluster-worker2         Ready    <none>          19d   v1.31.0
cka-qacluster-worker3         Ready    <none>          19d   v1.31.0
```

---

## 3Ô∏è‚É£ What Happens When a Kind Cluster is Created?

When you create a Kind cluster:

### ‚úÖ Flat Network Model

* Every Pod gets its own IP.
* Pods communicate across nodes without NAT.

### ‚úÖ CNI Plugin Installed Automatically

Kind installs **kindnet** by default.

```bash
kubectl get pods -n kube-system | grep kindnet
```

### ‚úÖ Service Discovery

Kubernetes Services provide stable endpoints:

* ClusterIP
* NodePort
* LoadBalancer

### ‚úÖ Pod-to-Pod Communication

Even across 3 worker nodes, Pods can talk seamlessly.

---

## üö® Why This Can Be a Problem

Because Kubernetes allows all traffic by default:

* ‚ùå A compromised Pod can attack others
* ‚ùå Multi-tenant workloads may interfere
* ‚ùå Databases may be exposed internally
* ‚ùå Security/compliance risks

---

## üèô Simple Analogy

Think of the cluster as a city with 3 districts (nodes):

* Kubernetes builds roads automatically.
* Everyone can travel freely.
* If you want traffic rules ‚Üí You create **NetworkPolicies**.

---

# 4Ô∏è‚É£ Creating a Cluster WITHOUT Default CNI

To control networking manually, we disable Kind‚Äôs default CNI.

`confignode.yml`

```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4

nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 32000
    hostPort: 32000
- role: worker
- role: worker
- role: worker

networking:
  disableDefaultCNI: true
  podSubnet: 192.168.0.0/16
```

### Key Settings

* `disableDefaultCNI: true`
  ‚Üí Do NOT install kindnet.
* `podSubnet: 192.168.0.0/16`
  ‚Üí Defines Pod IP range.

Create cluster:

```bash
kind create cluster --name cka-prodcluster --config confignode.yml
```

---

# 5Ô∏è‚É£ Problem: Nodes Show `NotReady`

```bash
kubectl get nodes
```

Output:

```
STATUS: NotReady
```

### Why?

Because we disabled the CNI ‚Äî and Kubernetes networking is not initialized.

From:

```bash
kubectl describe node <node-name>
```

You will see:

```
KubeletNotReady
NetworkPluginNotReady
cni plugin not initialized
```

---

# 6Ô∏è‚É£ Common Reasons for NotReady Nodes

* Docker not running properly
* Port conflicts (6443 etc.)
* CNI plugin missing
* Insufficient CPU/Memory

### Important Kubernetes Ports

* 6443 ‚Üí API Server
* 10250 ‚Üí Kubelet
* 30000‚Äì32767 ‚Üí NodePort range

---

# 7Ô∏è‚É£ Installing a Network Policy Provider

To fix the issue, install a CNI plugin that supports NetworkPolicy.

Example: Weave Net

```bash
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
```

Check:

```bash
kubectl get ds -n kube-system
```

Once `weave-net` becomes READY:

```bash
kubectl get nodes
```

Now:

```
STATUS: Ready
```

---

# 8Ô∏è‚É£ 3-Tier Architecture Example

Architecture:

Frontend ‚Üí Backend ‚Üí Database

---

## Deployment File: `laxmi3tire.yml`

Contains:

* frontend Pod + Service (nginx)
* backend Pod + Service (nginx)
* mysql Pod + Service (DB)

Apply:

```bash
kubectl apply -f laxmi3tire.yml
```

---

# 9Ô∏è‚É£ Testing Communication (Before NetworkPolicy)

Enter frontend Pod:

```bash
kubectl exec -it frontend -- bash
```

Test backend:

```bash
curl backend:80
```

‚úÖ Success

Test DB:

```bash
telnet db 3306
```

‚úÖ Connected

**This is insecure.**
Frontend should NOT directly access DB.

---

# üîü Creating NetworkPolicy

Goal:

Allow only **backend ‚Üí mysql**
Block **frontend ‚Üí mysql**

`netpolicy.yml`

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: db-test
spec:
  podSelector:
    matchLabels:
      name: mysql
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: backend
    ports:
    - port: 3306
```

Apply:

```bash
kubectl apply -f netpolicy.yml
```

---

# 1Ô∏è‚É£1Ô∏è‚É£ Testing After NetworkPolicy

From frontend:

```bash
telnet db 3306
```

‚ùå Connection timed out

Policy is working.

Now:

* Frontend ‚ùå cannot access DB
* Backend ‚úÖ can access DB

This is proper 3-tier isolation.

---

# 1Ô∏è‚É£2Ô∏è‚É£ Ingress vs Egress

* **Ingress** ‚Üí Incoming traffic to Pod
* **Egress** ‚Üí Outgoing traffic from Pod
* NetworkPolicy can control both directions.

---

# 1Ô∏è‚É£3Ô∏è‚É£ Port Forwarding

`kubectl port-forward` creates a secure tunnel from your local machine to a Pod or Service.

Example:

```bash
kubectl port-forward pod/my-pod 8080:80
```

Access:

```
http://localhost:8080
```

Local port 8080 ‚Üí Pod port 80

---

# ‚úÖ Summary

* Kubernetes allows all Pod communication by default.
* Kind installs kindnet automatically.
* Disabling CNI causes Nodes to be `NotReady`.
* Installing a CNI like Weave Net restores networking.
* NetworkPolicies enforce isolation.
* 3-tier architecture requires restricting DB access.
* NetworkPolicy ensures only backend talks to DB.

---

# üîê Final Takeaway

Kubernetes builds the roads.
NetworkPolicies install the traffic rules.

Without policies ‚Üí Everything talks to everything.
With policies ‚Üí Secure, production-ready isolation.
